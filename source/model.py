from typing import Listimport kerasimport tensorflow as tffrom tensorflow import set_random_seedfrom keras.initializers import npfrom keras.backend.tensorflow_backend import expand_dims, squeezefrom keras.layers import Input, Lambda, LSTM, CuDNNLSTM, Bidirectional, Dense, ReLU, TimeDistributed, \                         BatchNormalization, Dropout, ZeroPadding2D, Conv2D, Reshapeclass Model(keras.Model):               # This class is required for a consistent typing    is_adversarial = Falsedef deepspeech(is_gpu: bool, input_dim=80, output_dim=36, context=7,               units=1024, dropouts=(0.1, 0.1, 0), random_state=1) -> Model:    """    Model is adapted from: Deep Speech: Scaling up end-to-end speech recognition (https://arxiv.org/abs/1412.5567)    It is worth to know which default parameters are used:    - Conv2D:        strides: (1, 1)        padding: "valid"        dilatation_rate: 1        activation: "linear"        use_bias: True        data_format: "channels last"        kernel_initializer: "glorot_uniform"        bias_initializer: "zeros"    - Dense:        activation: "linear"        use_bias: True        kernel_initializer: "glorot_uniform"        bias_initializer: "zeros"    - LSTM (as for CuDNNLSTM):        use_bias: True,        kernel_initializer: "glorot_uniform"        recurrent_initializer: "orthogonal"        bias_initializer: "zeros"        unit_forget_bias: True        implementation: 1        return_state: False        go_backwards: False        stateful: False        unroll: False    """    np.random.seed(random_state)    set_random_seed(random_state)    rename = lambda name: Lambda(lambda x: x, name=name)                            # Create model under CPU scope and avoid OOM    with tf.device('/cpu:0'):                                                       # erors during concatenation a large distributed model.        input_tensor = Input([None, input_dim], name='X')                           # Define input tensor [time, features]        tensor = Lambda(expand_dims, arguments=dict(axis=-1))(input_tensor)         # Add 4th dim (channel)        tensor = ZeroPadding2D(padding=(context, 0))(tensor)                        # Fill zeros around time dimension        receptive_field = (2*context + 1, input_dim)                                # Take into account fore/back-ward context        tensor = Conv2D(filters=units, kernel_size=receptive_field)(tensor)         # Convolve signal in time dim        tensor = Lambda(squeeze, arguments=dict(axis=2))(tensor)                    # Squeeze into 3rd dim array        tensor = ReLU(max_value=20)(tensor)                                         # Add non-linearity        tensor = Dropout(rate=dropouts[0])(tensor)                                  # Use dropout as regularization        tensor = TimeDistributed(Dense(units))(tensor)                              # 2nd and 3rd FC layers do a feature        tensor = ReLU(max_value=20)(tensor)                                         # extraction base on the context        tensor = Dropout(rate=dropouts[1])(tensor)        tensor = TimeDistributed(Dense(units))(tensor)        tensor = ReLU(max_value=20)(tensor)        tensor = Dropout(rate=dropouts[2])(tensor)        tensor = Bidirectional(CuDNNLSTM(units, return_sequences=True)              # LSTM handle long dependencies                               if is_gpu else LSTM(units, return_sequences=True),                               merge_mode='sum')(tensor)        tensor = TimeDistributed(Dense(output_dim, activation='softmax'))(tensor)   # Return at each time step prob along characters        output_tensor = rename('char_probs')(tensor)        model = Model(input_tensor, output_tensor, name='DeepSpeech')    return modeldef deepspeech_custom(is_gpu: bool, layers: List[dict], input_dim: int, to_freeze: List[dict] = [], random_state=1) -> Model:    np.random.seed(random_state)    set_random_seed(random_state)    pop = lambda params, name: params.pop(name) if name in params else None    constructors = {        'BatchNormalization': lambda params: BatchNormalization(**params),        'Conv2D': lambda params: Conv2D(**params, name=name),        'Dense': lambda params: Dense(**params, name=name),        'DenseTimeDistributed': lambda params: TimeDistributed(Dense(**params), name=name),        'Dropout': lambda params: Dropout(**params),        'LSTM': lambda params: Bidirectional(CuDNNLSTM(**params) if is_gpu else                                             LSTM(activation='tanh', recurrent_activation='sigmoid', **params),                                             merge_mode='sum', name=name),        'ReLU': lambda params: ReLU(**params),        'ZeroPadding2D': lambda params: ZeroPadding2D(**params),        'expand_dims': lambda params: Lambda(expand_dims, arguments=params),        'squeeze': lambda params: Lambda(squeeze, arguments=params),        'squeeze_last_dims': lambda params: Reshape([-1, params['units']]),        'mean': lambda params: Lambda(tf.reduce_mean, arguments=params),        'rename': lambda name: Lambda(lambda x: x, name=name)    }    with tf.device('/cpu:0'):        input_tensor = Input([None, input_dim], name='X')        tensor = input_tensor        adversarial = False        for params in layers:            constructor_name = pop(params, 'constructor')            is_adversarial = pop(params, 'is_adversarial')            name = pop(params, 'name')                                  # `name` is implicit passed to constructors            constructor = constructors[constructor_name]                # Conv2D, TimeDistributed and Bidirectional.            layer = constructor(params)            if is_adversarial:                adversarial = True                mean = constructors['mean']({'axis': 1})                # The average vector (along time) is classified.                new_tensor = layer(mean(tensor))                        # The activation function should be sigmoid.                continue                                                # The Adversarial Network has two gradient paths.            tensor = layer(tensor)        rename = constructors['rename']                                 # Rename target tensors to have easy access to them.        char_probs = rename('char_probs')(tensor)        is_synthesized = rename('is_synthesized_prediction')(new_tensor) if adversarial else None        output_tensors = [char_probs, is_synthesized] if adversarial else [char_probs]        model = Model(input_tensor, output_tensors, name='DeepSpeech')        model.is_adversarial = adversarial        for params in to_freeze:            name = params.pop('name')            layer = model.get_layer(name)            layer.trainable = False    return model