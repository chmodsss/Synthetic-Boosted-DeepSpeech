
# Define how audio files are processing.
features_extractor:
  winlen: 0.025
  winstep: 0.01
  nfilt: 80
  winfunc: hamming


# Custom architecture can be created using `deepspeech-custom`.
model:
  name: deepspeech-custom
  input_dim: 80
  layers:
    - constructor: expand_dims
      axis: -1
    - constructor: ZeroPadding2D
      padding: [7, 20]
    - constructor: Conv2D
      name: base_1
      filters: 32
      kernel_size: [15, 41]
      strides: [2, 2]
    - constructor: squeeze_last_dims
      units: 1280
    - constructor: LSTM
      name: base_2
      units: 650
      return_sequences: True
    - constructor: LSTM
      name: base_3
      units: 650
      return_sequences: True
    - constructor: LSTM
      name: base_4
      units: 650
      return_sequences: True
    - constructor: LSTM
      name: base_5
      units: 650
      return_sequences: True
    - constructor: LSTM
      name: base_6
      units: 650
      return_sequences: True
    - constructor: Dense
      name: base_7
      units: 36
      activation: softmax


# The available optimizers are specified in: `get_optimizer` and
# come from `keras.optimizers` module.
optimizer:
  name: adam
  lr: 0.0001 # 1E-4
  beta_1: 0.9
  beta_2: 0.999
  epsilon: 0.00000001


# Set callbacks to get a view on internal states and statistics of the model
# during training.
callbacks:
  - name: TerminateOnNaN

  - name: ResultKeeper
    file_name: results.bin

  - name: CustomModelCheckpoint
    dir_name: checkpoints

  - name: LearningRateScheduler
    k: 1.2
    verbose: 1

  - name: CustomEarlyStopping
    mini_targets:
      5: 30
    monitor: val_loss
    patience: 2
    min_delta: 0.01


# Define method of decoding probabilities into transcription
decoder:
  name: tensorflow
  beam_size: 1024